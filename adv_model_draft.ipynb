{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - Advanced Model\n",
    "\n",
    "Divam Arora, Connor Moore, Hemanth Velan\n",
    "\n",
    "DSBA 6165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "* https://huggingface.co/datasets/gigaword\n",
    "* https://huggingface.co/docs/datasets/v1.11.0/splits.html\n",
    "* https://huggingface.co/docs/datasets/process#export\n",
    "* https://aparnamishra144.medium.com/how-to-change-string-data-or-text-data-of-a-column-to-lowercase-in-pandas-248a8ce4ae01\n",
    "* https://stackoverflow.com/questions/42135409/removing-a-character-from-entire-data-frame\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "* https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "* https://stackoverflow.com/questions/41425945/python-pandas-error-missing-unterminated-subpattern-at-position-2\n",
    "* https://stackoverflow.com/questions/28986489/how-to-replace-text-in-a-string-column-of-a-pandas-dataframe\n",
    "* https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "* https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/\n",
    "* https://www.analyticsvidhya.com/blog/2021/06/pre-processing-of-text-data-in-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to re-run the code from our EDA/pre-processing notebook that loads and prepares our dataset for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmoor197\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cmoor197\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cmoor197\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cmoor197\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import needed packages\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import evaluate\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as ds\n",
    "from evaluate import load\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# download stop word package from nltk library\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Because our dataset is pulled directly from Huggingface's datasets library, there is no need for a local copy of the data. Running the cell below creates an instance of the specified dataset in your workspace environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/gigaword\n",
    "# https://huggingface.co/docs/datasets/v1.11.0/splits.html\n",
    "\n",
    "# download gigaword dataset from Hugging Face dataset library\n",
    "train, test, validation = ds.load_dataset(\"gigaword\", split=[\"train\", \"test\", \"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 3803957\n",
      "})\n",
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 1951\n",
      "})\n",
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 189651\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# display the dataset splits\n",
    "print(train)\n",
    "print(test)\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df exported.\n",
      "Test df exported.\n",
      "Validation df exported.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/datasets/process#export\n",
    "\n",
    "# export the training dataset to a pandas dataframe and display\n",
    "df_train = train.to_pandas()\n",
    "print(\"Train df exported.\")\n",
    "\n",
    "# export the test dataset to a pandas dataframe\n",
    "df_test = test.to_pandas()\n",
    "print(\"Test df exported.\")\n",
    "\n",
    "# export the validation dataset to a pandas dataframe\n",
    "df_val = validation.to_pandas()\n",
    "print(\"Validation df exported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the train-test split\n",
    "The standard provided division between train, test, and validation is extremely unbalanced towards train (95%), and the dataset overall is far too large to run through our model in a reasonable timespan. We decided to shrink the train set to 70,000 entries, and concat the provided test and validation sets. From that combined test-val set we will extract a 25,000-entry test set and a 5,000 entry validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a british soldier was killed saturday by an ex...</td>\n",
       "      <td>british soldier killed in afghanistan blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukraine insists on building two new nuclear re...</td>\n",
       "      <td>ukraine insists on linking chernobyl closure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portuguese president mario soares will pay an ...</td>\n",
       "      <td>portugal 's president to visit angola next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aol stepped up its transformation from interne...</td>\n",
       "      <td>aol introduces new advertising network plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marine experts from wwf flew to the northern k...</td>\n",
       "      <td>suspected toxic algae bloom leaves thousands o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>hong kong 's benchmark hang seng index ended h...</td>\n",
       "      <td>hong kong stocks edged up after four straight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>former brazil coach carlos alberto parreira sa...</td>\n",
       "      <td>parreira says he 's close to an agreement to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>around ## youths on thursday protested outside...</td>\n",
       "      <td>latvian youths protest ban of UNK symbols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>ohio 's method of putting prisoners to death i...</td>\n",
       "      <td>ohio judge says state s lethal injection proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>yi zhang and lin xing made a #-# chinese finis...</td>\n",
       "      <td>china 's yi wins women 's triathlon at asian b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "0      a british soldier was killed saturday by an ex...   \n",
       "1      ukraine insists on building two new nuclear re...   \n",
       "2      portuguese president mario soares will pay an ...   \n",
       "3      aol stepped up its transformation from interne...   \n",
       "4      marine experts from wwf flew to the northern k...   \n",
       "...                                                  ...   \n",
       "69995  hong kong 's benchmark hang seng index ended h...   \n",
       "69996  former brazil coach carlos alberto parreira sa...   \n",
       "69997  around ## youths on thursday protested outside...   \n",
       "69998  ohio 's method of putting prisoners to death i...   \n",
       "69999  yi zhang and lin xing made a #-# chinese finis...   \n",
       "\n",
       "                                                 summary  \n",
       "0            british soldier killed in afghanistan blast  \n",
       "1      ukraine insists on linking chernobyl closure t...  \n",
       "2       portugal 's president to visit angola next month  \n",
       "3      aol introduces new advertising network plans t...  \n",
       "4      suspected toxic algae bloom leaves thousands o...  \n",
       "...                                                  ...  \n",
       "69995  hong kong stocks edged up after four straight ...  \n",
       "69996  parreira says he 's close to an agreement to c...  \n",
       "69997          latvian youths protest ban of UNK symbols  \n",
       "69998  ohio judge says state s lethal injection proce...  \n",
       "69999  china 's yi wins women 's triathlon at asian b...  \n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select 70,000 rows randomly from the train dataframe\n",
    "\n",
    "df_train_short = df_train.sample(n = 70000, random_state=2, ignore_index=True)\n",
    "\n",
    "df_train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine provided test and val sets and reseparate randomly into smaller subsets\n",
    "\n",
    "# concat test and validation sets\n",
    "test_val = [df_test, df_val]\n",
    "df_testval_bulk = pd.concat(test_val)\n",
    "\n",
    "# take a random sample of 30000 rows from the test and validation bulk set\n",
    "df_testval_short = df_testval_bulk.sample(n = 30000, random_state=3, ignore_index=True)\n",
    "\n",
    "# take a random 5000 row sample from the test-val subset\n",
    "df_val_short = df_testval_short.sample(n = 5000, random_state=4, ignore_index=True)\n",
    "\n",
    "# drop all rows taken for the validation sample from the test-val subset to create the test set\n",
    "df_test_short = df_testval_short.drop(df_val_short.index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "We decided to truncate our pre-processing pipeline slightly from our original model and submission because BART models are designed to accept full, grammatically correct sentences, so we thought passing more \"normal\" text may give the model better context and improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the methods required to perform this function were found in this article -\n",
    "# https://aparnamishra144.medium.com/how-to-change-string-data-or-text-data-of-a-column-to-lowercase-in-pandas-248a8ce4ae01\n",
    "# the function and comments are our original work\n",
    "\n",
    "# set all words in all rows to lower case\n",
    "\n",
    "def lower(df):\n",
    "    # vectorize strings in each row in summary column and set to lower case\n",
    "    df[\"summary\"] = df[\"summary\"].str.lower()\n",
    "    print(\"summary column lowercased\")\n",
    "    # vectorize strings in each row in document column and set to lower case\n",
    "    df[\"document\"] = df[\"document\"].str.lower()\n",
    "    print(\"document column lowercased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# geeks for geeks and pandas doc pages were used as template source code and informed about parameter options\n",
    "# stackoverflow posts helped with debugging issues\n",
    "# https://stackoverflow.com/questions/42135409/removing-a-character-from-entire-data-frame\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "# https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "# https://stackoverflow.com/questions/41425945/python-pandas-error-missing-unterminated-subpattern-at-position-2\n",
    "# https://stackoverflow.com/questions/28986489/how-to-replace-text-in-a-string-column-of-a-pandas-dataframe\n",
    "# comments and function are our original work, source code was modifed to fit our workspace\n",
    "\n",
    "# remove all symbols and punctuation\n",
    "\n",
    "# create instance of all punctuation symbols\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# since we learned there are lots of apostrophe s in the dataset during EDA, we will add this to our remove list\n",
    "punct_list = [\"'s\"]\n",
    "\n",
    "# add all punctuation from the premade variable to our new list\n",
    "for symbol in punctuation:\n",
    "    punct_list.append(symbol)\n",
    "\n",
    "# display the symbols included in our list\n",
    "print(punct_list)\n",
    "\n",
    "def remove_punctuation(df):\n",
    "    # for each symbol in our punctuation list\n",
    "    for symbol in punct_list:\n",
    "        # iterate through the dataframe and replace every instance of the symbol with an empty string\n",
    "        df[\"document\"] = df[\"document\"].str.replace(symbol, \"\", regex=False)\n",
    "        df[\"summary\"] = df[\"summary\"].str.replace(symbol, \"\", regex=False)\n",
    "    print(\"symbols removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data pre-processing pipeline\n",
    "\n",
    "def pre_proc(df):\n",
    "    # lowercase\n",
    "    lower(df)\n",
    "    # remove punctuation and symbols\n",
    "    remove_punctuation(df)\n",
    "    print(\"pre-processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary column lowercased\n",
      "document column lowercased\n",
      "symbols removed\n",
      "pre-processed successfully\n",
      "train df completed\n",
      "summary column lowercased\n",
      "document column lowercased\n",
      "symbols removed\n",
      "pre-processed successfully\n",
      "test df completed\n",
      "summary column lowercased\n",
      "document column lowercased\n",
      "symbols removed\n",
      "pre-processed successfully\n",
      "validation df completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a british soldier was killed saturday by an ex...</td>\n",
       "      <td>british soldier killed in afghanistan blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukraine insists on building two new nuclear re...</td>\n",
       "      <td>ukraine insists on linking chernobyl closure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portuguese president mario soares will pay an ...</td>\n",
       "      <td>portugal  president to visit angola next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aol stepped up its transformation from interne...</td>\n",
       "      <td>aol introduces new advertising network plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marine experts from wwf flew to the northern k...</td>\n",
       "      <td>suspected toxic algae bloom leaves thousands o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  a british soldier was killed saturday by an ex...   \n",
       "1  ukraine insists on building two new nuclear re...   \n",
       "2  portuguese president mario soares will pay an ...   \n",
       "3  aol stepped up its transformation from interne...   \n",
       "4  marine experts from wwf flew to the northern k...   \n",
       "\n",
       "                                             summary  \n",
       "0        british soldier killed in afghanistan blast  \n",
       "1  ukraine insists on linking chernobyl closure t...  \n",
       "2     portugal  president to visit angola next month  \n",
       "3  aol introduces new advertising network plans t...  \n",
       "4  suspected toxic algae bloom leaves thousands o...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the data pre-processing pipeline for each of the dataset splits\n",
    "\n",
    "pre_proc(df_train_short)\n",
    "print(\"train df completed\")\n",
    "pre_proc(df_val_short)\n",
    "print(\"test df completed\")\n",
    "pre_proc(df_test_short)\n",
    "print(\"validation df completed\")\n",
    "\n",
    "# display new format of data using training set\n",
    "df_train_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset splits are now pre-processed and ready for use with models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adv model writeup goes here\n",
    "(from canvas) \"Write about how your advanced model is different from your baseline model. Why did you choose the model architecture ? What evidence from the previous model milestone did you use to drive your decision making? Write at least 100 words.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to optimize model using this article - https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef\n",
    "\n",
    "and this notebook - https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "everything in cells below is from that source notebook, i modified it to fit our workspace and changed some of the parameters/functions to make sense for our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True)\n",
    "\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens_right(input_ids, pad_token_id):\n",
    "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
    "      This is taken directly from modeling_bart.py\n",
    "  \"\"\"\n",
    "  prev_output_tokens = input_ids.clone()\n",
    "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
    "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
    "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
    "  return prev_output_tokens\n",
    "\n",
    "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\"):\n",
    "  ''' Function that tokenizes a sentence \n",
    "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
    "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
    "  '''\n",
    "\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "  target_ids = []\n",
    "  tokenized_sentences = {}\n",
    "\n",
    "  for sentence in source_sentences:\n",
    "    encoded_dict = tokenizer(\n",
    "          sentence,\n",
    "          max_length=max_length,\n",
    "          padding=\"max_length\" if pad_to_max_length else None,\n",
    "          truncation=True,\n",
    "          return_tensors=return_tensors,\n",
    "          add_prefix_space = True\n",
    "      )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  input_ids = torch.cat(input_ids, dim = 0)\n",
    "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "\n",
    "  for sentence in target_sentences:\n",
    "    encoded_dict = tokenizer(\n",
    "          sentence,\n",
    "          max_length=max_length,\n",
    "          padding=\"max_length\" if pad_to_max_length else None,\n",
    "          truncation=True,\n",
    "          return_tensors=return_tensors,\n",
    "          add_prefix_space = True\n",
    "      )\n",
    "    # Shift the target ids to the right\n",
    "    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n",
    "    target_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "  target_ids = torch.cat(target_ids, dim = 0)\n",
    "  \n",
    "\n",
    "  batch = {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "      \"labels\": target_ids,\n",
    "  }\n",
    "\n",
    "  return batch\n",
    "\n",
    "\n",
    "def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n",
    "  '''\n",
    "  Function that noises a sentence by adding <mask> tokens\n",
    "  Args: sentence - the sentence to noise\n",
    "        percent_words - the percent of words to replace with <mask> tokens; the number is rounded up using math.ceil\n",
    "  Returns a noised sentence\n",
    "  '''\n",
    "  # Create a list item and copy\n",
    "  sentence_ = sentence_.split(' ')\n",
    "  sentence = sentence_.copy()\n",
    "  \n",
    "  num_words = math.ceil(len(sentence) * percent_words)\n",
    "  \n",
    "  # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n",
    "  # that word is often a rhyming word and plays an important role in song construction\n",
    "  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence)-1)))\n",
    "  \n",
    "  words_to_noise = random.sample(sample_tokens, num_words)\n",
    "  \n",
    "  # Swap out words, but not full stops\n",
    "  for pos in words_to_noise:\n",
    "      if sentence[pos] != '.':\n",
    "          sentence[pos] = replacement_token\n",
    "  \n",
    "  # Remove redundant spaces\n",
    "  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n",
    "  \n",
    "  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n",
    "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
    "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
    "  return sentence\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hparams dictionary to pass in the model\n",
    "# I realise that this isn't really how this is meant to be used, but having this here reminds me that I can edit it when I need\n",
    "params = argparse.Namespace()\n",
    "\n",
    "params.freeze_encoder = True\n",
    "params.freeze_embeds = True\n",
    "params.eval_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "  # Instantiate the model\n",
    "  def __init__(self, learning_rate, tokenizer, model, params):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.model = model\n",
    "    self.learning_rate = learning_rate\n",
    "    # self.freeze_encoder = freeze_encoder\n",
    "    # self.freeze_embeds_ = freeze_embeds\n",
    "    self.params = params\n",
    "\n",
    "    if self.params.freeze_encoder:\n",
    "      freeze_params(self.model.get_encoder())\n",
    "\n",
    "    if self.params.freeze_embeds:\n",
    "      self.freeze_embeds()\n",
    "  \n",
    "  def freeze_embeds(self):\n",
    "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
    "    freeze_params(self.model.model.shared)\n",
    "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "      freeze_params(d.embed_positions)\n",
    "      freeze_params(d.embed_tokens)\n",
    "\n",
    "  # Do a forward pass through the model\n",
    "  def forward(self, input_ids, **kwargs):\n",
    "    return self.model(input_ids, **kwargs)\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Load the data into variables\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "\n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "    # Create the loss function\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    # Calculate the loss on the un-shifted tokens\n",
    "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss':loss}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss': val_loss}\n",
    "  \n",
    "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
    "  def generate_text(self, inputs, max_length, min_length, length_penalty, num_beams, early_stopping=True):\n",
    "    ''' Function to generate text '''\n",
    "    generated_id = self.model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=length_penalty, num_beams=num_beams, early_stopping=early_stopping)\n",
    "    return generated_id\n",
    "\n",
    "def freeze_params(model):\n",
    "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
    "      adapted from finetune.py '''\n",
    "  for layer in model.parameters():\n",
    "    layer.requires_grade = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloading module as per the PyTorch Lightning Docs\n",
    "class SummaryDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, tokenizer, train, test, validate, batch_size):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.batch_size = batch_size\n",
    "    self.train = train\n",
    "    self.test = test\n",
    "    self.validate = validate\n",
    "\n",
    "  # encode the sentences using the tokenizer  \n",
    "  def setup(self, stage):\n",
    "    self.train = encode_sentences(self.tokenizer, self.train['document'], self.train['summary'])\n",
    "    self.validate = encode_sentences(self.tokenizer, self.validate['document'], self.validate['summary'])\n",
    "    self.test = encode_sentences(self.tokenizer, self.test['document'], self.test['summary'])\n",
    "\n",
    "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
    "  def train_dataloader(self):\n",
    "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n",
    "    train_data = DataLoader(dataset, num_workers=7, persistent_workers=True, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
    "    return train_data\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n",
    "    val_data = DataLoader(dataset, num_workers=7, persistent_workers=True, batch_size = self.batch_size)                       \n",
    "    return val_data\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n",
    "    test_data = DataLoader(dataset, num_workers=7, persistent_workers=True, batch_size = self.batch_size)                   \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into the model for training\n",
    "summary_data = SummaryDataModule(tokenizer, df_train_short, df_test_short, df_val_short, batch_size = 16)\n",
    "\n",
    "model = LitModel(learning_rate=2e-5, tokenizer=tokenizer, model=bart_model, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=False,\n",
    "                     max_epochs = 1,\n",
    "                     min_epochs = 1,\n",
    "                     enable_model_summary=True,\n",
    "                     enable_progress_bar=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 139 M \n",
      "-------------------------------------------------------\n",
      "139 M     Trainable params\n",
      "0         Non-trainable params\n",
      "139 M     Total params\n",
      "557.682   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4375/4375 [3:44:04<00:00,  0.33it/s]             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4375/4375 [3:44:13<00:00,  0.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit the instantiated model to the data\n",
    "trainer.fit(model, summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of using that source notebook - trying out the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW VERSION OF RUNBART with no NA outputs\n",
    "\n",
    "\n",
    "def runBart(df):\n",
    "\n",
    "    # Empty lists for predictions and performance timestamps\n",
    "    predictions = []\n",
    "    times = []\n",
    "\n",
    "    # For the number of rows in the given dataframe\n",
    "    for i in range(len(df)):\n",
    "        # Create a start timestamp\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Create a document instance using the row's entry for the stringified document\n",
    "        doc = df.iloc[i][\"document\"]\n",
    "\n",
    "        # Encoding inputs using BART tokenizer \n",
    "        inputs = tokenizer.encode(doc, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "        # Generate vectorized summary using encoded inputs\n",
    "        summary_ids = model.generate_text(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "        # Decode the summary into a human-readable format\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Append the predicted summary to a list of predictions\n",
    "        predictions.append(summary)\n",
    "\n",
    "        # Create an end timestamp\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        # Calculate computation speed\n",
    "        speed = end - start\n",
    "\n",
    "        # Append computation speed to list\n",
    "        times.append(speed)\n",
    "\n",
    "        # If the iteration is a multiple of 1000\n",
    "        if i % 5000 == 0:\n",
    "            # Calculate the average computation time per row so far and print\n",
    "            avg_time = sum(times) / len(times)\n",
    "            print(\"Average time per row at\", i, \"row:\", avg_time)\n",
    "\n",
    "    # Create a new column for the dataframe using the predictions generated and return the modified dataframe\n",
    "    df[\"BART_Pred\"] = predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per row at 0 row: 2.058996300000217\n",
      "Average time per row at 5000 row: 1.918337959508114\n",
      "Average time per row at 10000 row: 1.9208283956404233\n",
      "Average time per row at 15000 row: 1.9187569718818536\n",
      "Average time per row at 20000 row: 1.9171497695365232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>BART_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>japanese electronics giant toshiba said tuesda...</td>\n",
       "      <td>toshiba profits  times up in third quarter</td>\n",
       "      <td>toshiba net profits grow more than  times yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>michael campbell opened a unk lead on defendin...</td>\n",
       "      <td>campbell puts defending champion woosnam in tr...</td>\n",
       "      <td>campbell leads woosnam after  holes in quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>iran on tuesday dismissed the allegation by th...</td>\n",
       "      <td>iran denies allegation on its military deployment</td>\n",
       "      <td>iran dismisses alawsat claim on southern bord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>turkish foreign minister and deputy prime mini...</td>\n",
       "      <td>turkish fm hails eu plan to end economic sanct...</td>\n",
       "      <td>turkish fm says eu proposal on cypriot cyprio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>patricia mcgovern  the former senate ways and ...</td>\n",
       "      <td>former senator joins governor race</td>\n",
       "      <td>mcgovern announces campaign for governor of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>three activists are charged with staging an un...</td>\n",
       "      <td>charges against activists could set precedent ...</td>\n",
       "      <td>hong kong activists charged with unauthorized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>a prominent fatah leader and his   yearold son...</td>\n",
       "      <td>father son killed in fatahhamas fight in gaza</td>\n",
       "      <td>fatah leader hamas killed in gaza city fighti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>trustees at virginia union university  one of ...</td>\n",
       "      <td>wilder in running to head virginia union</td>\n",
       "      <td>virginia union trustees considering douglas w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>patrouille de france   lrb paf rrb the famous...</td>\n",
       "      <td>french famous unk to present aerobatics shows ...</td>\n",
       "      <td>china  aerobatic team to present aerobatics s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>the relentless insurgency in the sunni muslim ...</td>\n",
       "      <td>us troops battle resistance fighters west of b...</td>\n",
       "      <td>roadside bombings kill  american soldier in b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "5000   japanese electronics giant toshiba said tuesda...   \n",
       "5001   michael campbell opened a unk lead on defendin...   \n",
       "5002   iran on tuesday dismissed the allegation by th...   \n",
       "5003   turkish foreign minister and deputy prime mini...   \n",
       "5004   patricia mcgovern  the former senate ways and ...   \n",
       "...                                                  ...   \n",
       "29995  three activists are charged with staging an un...   \n",
       "29996  a prominent fatah leader and his   yearold son...   \n",
       "29997  trustees at virginia union university  one of ...   \n",
       "29998   patrouille de france   lrb paf rrb the famous...   \n",
       "29999  the relentless insurgency in the sunni muslim ...   \n",
       "\n",
       "                                                 summary  \\\n",
       "5000          toshiba profits  times up in third quarter   \n",
       "5001   campbell puts defending champion woosnam in tr...   \n",
       "5002   iran denies allegation on its military deployment   \n",
       "5003   turkish fm hails eu plan to end economic sanct...   \n",
       "5004                  former senator joins governor race   \n",
       "...                                                  ...   \n",
       "29995  charges against activists could set precedent ...   \n",
       "29996      father son killed in fatahhamas fight in gaza   \n",
       "29997           wilder in running to head virginia union   \n",
       "29998  french famous unk to present aerobatics shows ...   \n",
       "29999  us troops battle resistance fighters west of b...   \n",
       "\n",
       "                                               BART_Pred  \n",
       "5000    toshiba net profits grow more than  times yea...  \n",
       "5001    campbell leads woosnam after  holes in quarte...  \n",
       "5002    iran dismisses alawsat claim on southern bord...  \n",
       "5003    turkish fm says eu proposal on cypriot cyprio...  \n",
       "5004    mcgovern announces campaign for governor of t...  \n",
       "...                                                  ...  \n",
       "29995   hong kong activists charged with unauthorized...  \n",
       "29996   fatah leader hamas killed in gaza city fighti...  \n",
       "29997   virginia union trustees considering douglas w...  \n",
       "29998   china  aerobatic team to present aerobatics s...  \n",
       "29999   roadside bombings kill  american soldier in b...  \n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runBart(df_test_short)\n",
    "\n",
    "df_test_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were 0 empty predictions generated.\n"
     ]
    }
   ],
   "source": [
    "# check generated predictions for NaN values\n",
    "\n",
    "# count null values in BART pred columnm\n",
    "null_predictions = df_test_short['BART_Pred'].isna().sum()\n",
    "\n",
    "print(\"there were\", null_predictions, \"empty predictions generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improvement over our baseline model, which generated a large number of null values as predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTScore Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\cmoor197\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bertscore\\cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b (last modified on Fri Nov  3 16:56:45 2023) since it couldn't be found locally at evaluate-metric--bertscore, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bert_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cmoor197\\Documents\\ai_work\\text_summarization\\adv_model_draft.ipynb Cell 34\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cmoor197/Documents/ai_work/text_summarization/adv_model_draft.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# initialize BERTScore metric\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cmoor197/Documents/ai_work/text_summarization/adv_model_draft.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m bertscore \u001b[39m=\u001b[39m load(\u001b[39m\"\u001b[39;49m\u001b[39mbertscore\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\evaluate\\loading.py:751\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[39m=\u001b[39m DownloadMode(download_mode \u001b[39mor\u001b[39;00m DownloadMode\u001b[39m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m    748\u001b[0m evaluation_module \u001b[39m=\u001b[39m evaluation_module_factory(\n\u001b[0;32m    749\u001b[0m     path, module_type\u001b[39m=\u001b[39mmodule_type, revision\u001b[39m=\u001b[39mrevision, download_config\u001b[39m=\u001b[39mdownload_config, download_mode\u001b[39m=\u001b[39mdownload_mode\n\u001b[0;32m    750\u001b[0m )\n\u001b[1;32m--> 751\u001b[0m evaluation_cls \u001b[39m=\u001b[39m import_main_class(evaluation_module\u001b[39m.\u001b[39;49mmodule_path)\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[39m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[39m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[39m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n\u001b[0;32m    763\u001b[0m \u001b[39mif\u001b[39;00m module_type \u001b[39mand\u001b[39;00m module_type \u001b[39m!=\u001b[39m evaluation_instance\u001b[39m.\u001b[39mmodule_type:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\evaluate\\loading.py:76\u001b[0m, in \u001b[0;36mimport_main_class\u001b[1;34m(module_path)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimport_main_class\u001b[39m(module_path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Type[DatasetBuilder], Type[EvaluationModule]]]:\n\u001b[0;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Import a module at module_path and return its main class, a Metric by default\"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(module_path)\n\u001b[0;32m     77\u001b[0m     main_cls_type \u001b[39m=\u001b[39m EvaluationModule\n\u001b[0;32m     79\u001b[0m     \u001b[39m# Find the main class in our imported module\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bertscore\\cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b\\bertscore.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcontextlib\u001b[39;00m \u001b[39mimport\u001b[39;00m contextmanager\n\u001b[1;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbert_score\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bert_score'"
     ]
    }
   ],
   "source": [
    "# initialize BERTScore metric\n",
    "\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating BERTScore metrics for model predictions\n",
    "\n",
    "# create list of prediction outputs\n",
    "test_predictions = list(df_test_short[\"BART_Pred\"].astype(str))\n",
    "# create list of true outputs\n",
    "test_references = list(df_test_short[\"summary\"].astype(str))\n",
    "# calculate BERTScore values comparing model predictions with true summaries\n",
    "test_results_bert = bertscore.compute(predictions=test_predictions, references=test_references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average precision, recall and F1 scores from BERTScore model based on model predictions\n",
    "\n",
    "# create list of result keys\n",
    "test_keys = list(test_results_bert.keys())\n",
    "\n",
    "# for number of values in keylist-1\n",
    "for k in range(len(test_keys)-1):\n",
    "    # sum total of all result values\n",
    "    s_test = sum(test_results_bert[test_keys[k]])\n",
    "    # calculate the total number of result values\n",
    "    le_test = len(test_results_bert[test_keys[k]])\n",
    "    # compute average result value\n",
    "    avg_test = s_test/le_test\n",
    "\n",
    "    print(\"test set result:\")\n",
    "    print(\"Average {} is {}\".format(test_keys[k], avg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ROGUE metrics model\n",
    "\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ROGUE metrics scores for train and test model outputs\n",
    "\n",
    "# compute ROGUE metrics scores comparing model predictions with true outputs\n",
    "test_results_rogue = rouge.compute(predictions=test_predictions, references=test_references)\n",
    "\n",
    "print(\"test set results:\")\n",
    "print(test_results_rogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model performance results writeup goes here\n",
    "(from canvas) \"You have been able to create a training and testing set from your data (or it has already been given to you). We want to see evidence that you were able to train your advanced model and have performance metrics. How does your model perform on the metrics you have chosen from your previous submission?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
