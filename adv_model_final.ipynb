{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - Advanced Model\n",
    "\n",
    "Divam Arora, Connor Moore, Hemanth Velan\n",
    "\n",
    "DSBA 6165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "* https://huggingface.co/datasets/gigaword\n",
    "* https://huggingface.co/docs/datasets/process#export\n",
    "* https://huggingface.co/docs/datasets/v1.11.0/splits.html\n",
    "* https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "* https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "* https://www.analyticsvidhya.com/blog/2021/06/pre-processing-of-text-data-in-nlp/\n",
    "* https://stackoverflow.com/questions/42135409/removing-a-character-from-entire-data-frame\n",
    "* https://discuss.huggingface.co/t/train-bart-for-conditional-generation-e-g-summarization/1904\n",
    "* https://github.com/huggingface/transformers/blob/main/examples/pytorch/summarization/README.md\n",
    "* https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/\n",
    "* https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef\n",
    "* https://stackoverflow.com/questions/28986489/how-to-replace-text-in-a-string-column-of-a-pandas-dataframe\n",
    "* https://huggingface.co/docs/transformers/v4.35.0/en/model_doc/bart#transformers.BartForConditionalGeneration\n",
    "* https://stackoverflow.com/questions/41425945/python-pandas-error-missing-unterminated-subpattern-at-position-2\n",
    "* https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "* https://aparnamishra144.medium.com/how-to-change-string-data-or-text-data-of-a-column-to-lowercase-in-pandas-248a8ce4ae01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to re-run the code from our EDA/pre-processing notebook that loads and prepares our dataset for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cmoor197\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cmoor197\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cmoor197\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import needed packages\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import evaluate\n",
    "import argparse\n",
    "import bert_score\n",
    "import rouge_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as ds\n",
    "from evaluate import load\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# download stop word package from nltk library\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Because our dataset is pulled directly from Huggingface's datasets library, there is no need for a local copy of the data. Running the cell below creates an instance of the specified dataset in your workspace environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/gigaword\n",
    "# https://huggingface.co/docs/datasets/v1.11.0/splits.html\n",
    "\n",
    "# download gigaword dataset from Hugging Face dataset library\n",
    "train, test, validation = ds.load_dataset(\"gigaword\", split=[\"train\", \"test\", \"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 3803957\n",
      "})\n",
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 1951\n",
      "})\n",
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 189651\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# display the dataset splits\n",
    "print(train)\n",
    "print(test)\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df exported.\n",
      "Test df exported.\n",
      "Validation df exported.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/datasets/process#export\n",
    "\n",
    "# export the training dataset to a pandas dataframe and display\n",
    "df_train = train.to_pandas()\n",
    "print(\"Train df exported.\")\n",
    "\n",
    "# export the test dataset to a pandas dataframe\n",
    "df_test = test.to_pandas()\n",
    "print(\"Test df exported.\")\n",
    "\n",
    "# export the validation dataset to a pandas dataframe\n",
    "df_val = validation.to_pandas()\n",
    "print(\"Validation df exported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the train-test split\n",
    "The standard provided division between train, test, and validation is extremely unbalanced towards train (95%), and the dataset overall is far too large to run through our model in a reasonable timespan. We decided to shrink the train set to 70,000 entries, and concat the provided test and validation sets. From that combined test-val set we will extract a 25,000-entry test set and a 5,000 entry validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a british soldier was killed saturday by an ex...</td>\n",
       "      <td>british soldier killed in afghanistan blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukraine insists on building two new nuclear re...</td>\n",
       "      <td>ukraine insists on linking chernobyl closure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portuguese president mario soares will pay an ...</td>\n",
       "      <td>portugal 's president to visit angola next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aol stepped up its transformation from interne...</td>\n",
       "      <td>aol introduces new advertising network plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marine experts from wwf flew to the northern k...</td>\n",
       "      <td>suspected toxic algae bloom leaves thousands o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>hong kong 's benchmark hang seng index ended h...</td>\n",
       "      <td>hong kong stocks edged up after four straight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>former brazil coach carlos alberto parreira sa...</td>\n",
       "      <td>parreira says he 's close to an agreement to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>around ## youths on thursday protested outside...</td>\n",
       "      <td>latvian youths protest ban of UNK symbols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>ohio 's method of putting prisoners to death i...</td>\n",
       "      <td>ohio judge says state s lethal injection proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>yi zhang and lin xing made a #-# chinese finis...</td>\n",
       "      <td>china 's yi wins women 's triathlon at asian b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "0      a british soldier was killed saturday by an ex...   \n",
       "1      ukraine insists on building two new nuclear re...   \n",
       "2      portuguese president mario soares will pay an ...   \n",
       "3      aol stepped up its transformation from interne...   \n",
       "4      marine experts from wwf flew to the northern k...   \n",
       "...                                                  ...   \n",
       "69995  hong kong 's benchmark hang seng index ended h...   \n",
       "69996  former brazil coach carlos alberto parreira sa...   \n",
       "69997  around ## youths on thursday protested outside...   \n",
       "69998  ohio 's method of putting prisoners to death i...   \n",
       "69999  yi zhang and lin xing made a #-# chinese finis...   \n",
       "\n",
       "                                                 summary  \n",
       "0            british soldier killed in afghanistan blast  \n",
       "1      ukraine insists on linking chernobyl closure t...  \n",
       "2       portugal 's president to visit angola next month  \n",
       "3      aol introduces new advertising network plans t...  \n",
       "4      suspected toxic algae bloom leaves thousands o...  \n",
       "...                                                  ...  \n",
       "69995  hong kong stocks edged up after four straight ...  \n",
       "69996  parreira says he 's close to an agreement to c...  \n",
       "69997          latvian youths protest ban of UNK symbols  \n",
       "69998  ohio judge says state s lethal injection proce...  \n",
       "69999  china 's yi wins women 's triathlon at asian b...  \n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select 70,000 rows randomly from the train dataframe\n",
    "\n",
    "df_train_short = df_train.sample(n = 70000, random_state=2, ignore_index=True)\n",
    "\n",
    "df_train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine provided test and val sets and reseparate randomly into smaller subsets\n",
    "\n",
    "# concat test and validation sets\n",
    "test_val = [df_test, df_val]\n",
    "df_testval_bulk = pd.concat(test_val)\n",
    "\n",
    "# take a random sample of 30000 rows from the test and validation bulk set\n",
    "df_testval_short = df_testval_bulk.sample(n = 30000, random_state=3, ignore_index=True)\n",
    "\n",
    "# take a random 5000 row sample from the test-val subset\n",
    "df_val_short = df_testval_short.sample(n = 5000, random_state=4, ignore_index=True)\n",
    "\n",
    "# drop all rows taken for the validation sample from the test-val subset to create the test set\n",
    "df_test_short = df_testval_short.drop(df_val_short.index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "We decided to truncate our pre-processing pipeline slightly from our baseline model notebook (removing lemmatization and not vectorizing text prior to passing it to the BART pretrained tokenizer) because BART models are designed to accept full, grammatically correct sentences. We thought passing more \"normal\" text during training may give the model better context and improve learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the methods required to perform this function were found in this article -\n",
    "# https://aparnamishra144.medium.com/how-to-change-string-data-or-text-data-of-a-column-to-lowercase-in-pandas-248a8ce4ae01\n",
    "# the function and comments are our original work\n",
    "\n",
    "# set all words in all rows to lower case\n",
    "\n",
    "def lower(df):\n",
    "    # vectorize strings in each row in summary column and set to lower case\n",
    "    df[\"summary\"] = df[\"summary\"].str.lower()\n",
    "    print(\"summary column lowercased\")\n",
    "    # vectorize strings in each row in document column and set to lower case\n",
    "    df[\"document\"] = df[\"document\"].str.lower()\n",
    "    print(\"document column lowercased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# geeks for geeks and pandas doc pages were used as template source code and informed about parameter options\n",
    "# stackoverflow posts helped with debugging issues\n",
    "# https://stackoverflow.com/questions/42135409/removing-a-character-from-entire-data-frame\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "# https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "# https://stackoverflow.com/questions/41425945/python-pandas-error-missing-unterminated-subpattern-at-position-2\n",
    "# https://stackoverflow.com/questions/28986489/how-to-replace-text-in-a-string-column-of-a-pandas-dataframe\n",
    "# comments and function are our original work, source code was modifed to fit our workspace\n",
    "\n",
    "# remove all symbols and punctuation\n",
    "\n",
    "# create instance of all punctuation symbols\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# since we learned there are lots of apostrophe s in the dataset during EDA, we will add this to our remove list\n",
    "punct_list = [\"'s\"]\n",
    "\n",
    "# add all punctuation from the premade variable to our new list\n",
    "for symbol in punctuation:\n",
    "    punct_list.append(symbol)\n",
    "\n",
    "# display the symbols included in our list\n",
    "print(punct_list)\n",
    "\n",
    "def remove_punctuation(df):\n",
    "    # for each symbol in our punctuation list\n",
    "    for symbol in punct_list:\n",
    "        # iterate through the dataframe and replace every instance of the symbol with an empty string\n",
    "        df[\"document\"] = df[\"document\"].str.replace(symbol, \"\", regex=False)\n",
    "        df[\"summary\"] = df[\"summary\"].str.replace(symbol, \"\", regex=False)\n",
    "    print(\"symbols removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data pre-processing pipeline\n",
    "\n",
    "def pre_proc(df):\n",
    "    # lowercase\n",
    "    lower(df)\n",
    "    # remove punctuation and symbols\n",
    "    remove_punctuation(df)\n",
    "    print(\"pre-processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary column lowercased\n",
      "document column lowercased\n",
      "symbols removed\n",
      "pre-processed successfully\n",
      "train df completed\n",
      "summary column lowercased\n",
      "document column lowercased\n",
      "symbols removed\n",
      "pre-processed successfully\n",
      "test df completed\n",
      "summary column lowercased\n",
      "document column lowercased\n",
      "symbols removed\n",
      "pre-processed successfully\n",
      "validation df completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a british soldier was killed saturday by an ex...</td>\n",
       "      <td>british soldier killed in afghanistan blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukraine insists on building two new nuclear re...</td>\n",
       "      <td>ukraine insists on linking chernobyl closure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portuguese president mario soares will pay an ...</td>\n",
       "      <td>portugal  president to visit angola next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aol stepped up its transformation from interne...</td>\n",
       "      <td>aol introduces new advertising network plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marine experts from wwf flew to the northern k...</td>\n",
       "      <td>suspected toxic algae bloom leaves thousands o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  a british soldier was killed saturday by an ex...   \n",
       "1  ukraine insists on building two new nuclear re...   \n",
       "2  portuguese president mario soares will pay an ...   \n",
       "3  aol stepped up its transformation from interne...   \n",
       "4  marine experts from wwf flew to the northern k...   \n",
       "\n",
       "                                             summary  \n",
       "0        british soldier killed in afghanistan blast  \n",
       "1  ukraine insists on linking chernobyl closure t...  \n",
       "2     portugal  president to visit angola next month  \n",
       "3  aol introduces new advertising network plans t...  \n",
       "4  suspected toxic algae bloom leaves thousands o...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the data pre-processing pipeline for each of the dataset splits\n",
    "# minus the lemmatization and tokenizer steps from the baseline notebook\n",
    "\n",
    "pre_proc(df_train_short)\n",
    "print(\"train df completed\")\n",
    "pre_proc(df_val_short)\n",
    "print(\"test df completed\")\n",
    "pre_proc(df_test_short)\n",
    "print(\"validation df completed\")\n",
    "\n",
    "# display new format of data using training set\n",
    "df_train_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset splits are now pre-processed and ready for use with models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model Choices\n",
    "*(from canvas) \"Write about how your advanced model is different from your baseline model. Why did you choose the model architecture? What evidence from the previous model milestone did you use to drive your decision making? Write at least 100 words.\"*\n",
    "\n",
    "The main difference between our advanced model and the baseline model is that in this advanced approach we attempted to train and fine tune the BART-base model for our text summarization task, rather than just using the BART-base model in its original form as we did with our baseline model. After strategies for fine-tuning and specializing transformer models were discussed in class, we wanted to try this with our model. BART, as a pretrained model, is very effective at text summarization out of the box, but we thought fine-tuning our model could potentially provide significant performance gains and make the model better at text summarization specifically. After some research, we found that BERT models seem to have far more examples of fine-tuning and task-oriented specialization than BART models, but we wanted to keep the same core transformer architecture as the baseline model to provide the best possible performance comparison. We were eventually able to find an example of someone fine-tuning a BART model for a specific task (linked in the towards data science article below), so we used that article and its associated google colab notebook as inspiration for model training and fine-tuning.\n",
    "\n",
    "A change from the baseline model to this one that was a direct result of baseline performance is the adjustment we made to our \"runBART\" prediction function. During our baseline model test, the model produced an extremely large number of NaN empty predictions, which skews the metric scores (in addition to being completely useless from an end user perspective). Using the latter three sources listed below and some testing, we were able to determine a hyperparameter setup for the BART model's encode() and generate() functions that eliminated this problem completely. This advanced model implements these changes, and in 25,000 predictions output zero null values.\n",
    "\n",
    "# Sources -\n",
    "* https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef\n",
    "* https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "* https://github.com/huggingface/transformers/blob/main/examples/pytorch/summarization/README.md\n",
    "* https://huggingface.co/docs/transformers/v4.35.0/en/model_doc/bart#transformers.BartForConditionalGeneration\n",
    "* https://discuss.huggingface.co/t/train-bart-for-conditional-generation-e-g-summarization/1904\n",
    "\n",
    "\n",
    "# Train and fine-tune BART model for text summarization\n",
    "We attempted to optimize and fine tune our BART model taking inspiration from this article - https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef\n",
    "\n",
    "using this affiliated notebook as source code - https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "All cells with that colab link as the first line comment are based on the source notebook, we modified the approach utilized in that notebook and article to fit our workspace and changed some of the parameters and functions for our application. Variations are described in the cells with comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# load BART base model and tokenizer\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True)\n",
    "\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# these functions are direct from the source notebook, these functions are used for the model training process\n",
    "# several of the functions included in the source notebook have been removed because they do not fit our task\n",
    "\n",
    "def shift_tokens_right(input_ids, pad_token_id):\n",
    "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
    "      This is taken directly from modeling_bart.py\n",
    "  \"\"\"\n",
    "  prev_output_tokens = input_ids.clone()\n",
    "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
    "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
    "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
    "  return prev_output_tokens\n",
    "\n",
    "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\"):\n",
    "  ''' Function that tokenizes a sentence \n",
    "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
    "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
    "  '''\n",
    "\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "  target_ids = []\n",
    "  tokenized_sentences = {}\n",
    "\n",
    "  for sentence in source_sentences:\n",
    "    encoded_dict = tokenizer(\n",
    "          sentence,\n",
    "          max_length=max_length,\n",
    "          padding=\"max_length\" if pad_to_max_length else None,\n",
    "          truncation=True,\n",
    "          return_tensors=return_tensors,\n",
    "          add_prefix_space = True\n",
    "      )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  input_ids = torch.cat(input_ids, dim = 0)\n",
    "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "\n",
    "  for sentence in target_sentences:\n",
    "    encoded_dict = tokenizer(\n",
    "          sentence,\n",
    "          max_length=max_length,\n",
    "          padding=\"max_length\" if pad_to_max_length else None,\n",
    "          truncation=True,\n",
    "          return_tensors=return_tensors,\n",
    "          add_prefix_space = True\n",
    "      )\n",
    "\n",
    "    target_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "  target_ids = torch.cat(target_ids, dim = 0)\n",
    "  \n",
    "\n",
    "  batch = {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "      \"labels\": target_ids,\n",
    "  }\n",
    "\n",
    "  return batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# this cell is also from the source notebook, setting initial states for hyperparameters prior to training\n",
    "\n",
    "# create a baseline for the hyperparameters dictionary to pass to the model for training\n",
    "params = argparse.Namespace()\n",
    "\n",
    "params.freeze_encoder = True\n",
    "params.freeze_embeds = True\n",
    "params.eval_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# this model class is from the source notebook. variables/parameters and some of the functions were modified to fit our workspace and model task (summarization)\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "  # Instantiate the model\n",
    "  def __init__(self, learning_rate, tokenizer, model, params):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.model = model\n",
    "    self.learning_rate = learning_rate\n",
    "    self.params = params\n",
    "\n",
    "    if self.params.freeze_encoder:\n",
    "      freeze_params(self.model.get_encoder())\n",
    "\n",
    "    if self.params.freeze_embeds:\n",
    "      self.freeze_embeds()\n",
    "  \n",
    "  def freeze_embeds(self):\n",
    "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
    "    freeze_params(self.model.model.shared)\n",
    "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "      freeze_params(d.embed_positions)\n",
    "      freeze_params(d.embed_tokens)\n",
    "\n",
    "  # Do a forward pass through the model\n",
    "  def forward(self, input_ids, **kwargs):\n",
    "    return self.model(input_ids, **kwargs)\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Load the data into variables\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "\n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "    # Create the loss function\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    # Calculate the loss on the un-shifted tokens\n",
    "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss':loss}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss': val_loss}\n",
    "  \n",
    "  # this function was heavily modified from the source code to fit our application, utilizing the new configuration we found to eliminate NaN prediction outputs\n",
    "  def generate_text(self, inputs, max_length, min_length, length_penalty, num_beams, early_stopping=True):\n",
    "    ''' Function to generate text '''\n",
    "    generated_id = self.model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=length_penalty, num_beams=num_beams, early_stopping=early_stopping)\n",
    "    return generated_id\n",
    "\n",
    "def freeze_params(model):\n",
    "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
    "      adapted from finetune.py '''\n",
    "  for layer in model.parameters():\n",
    "    layer.requires_grade = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# this class is also from the source notebook. input parameters and all of the dataframe column name calls for the \"setup\" function had to be modified for our workspace\n",
    "\n",
    "# Create a dataloading module as per the PyTorch Lightning Docs\n",
    "class SummaryDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, tokenizer, train, test, validate, batch_size):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.batch_size = batch_size\n",
    "    self.train = train\n",
    "    self.test = test\n",
    "    self.validate = validate\n",
    "\n",
    "  # encode the sentences using the tokenizer  \n",
    "  def setup(self, stage):\n",
    "    self.train = encode_sentences(self.tokenizer, self.train['document'], self.train['summary'])\n",
    "    self.validate = encode_sentences(self.tokenizer, self.validate['document'], self.validate['summary'])\n",
    "    self.test = encode_sentences(self.tokenizer, self.test['document'], self.test['summary'])\n",
    "\n",
    "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
    "  def train_dataloader(self):\n",
    "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n",
    "    train_data = DataLoader(dataset, num_workers=7, persistent_workers=True, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
    "    return train_data\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n",
    "    val_data = DataLoader(dataset, num_workers=7, persistent_workers=True, batch_size = self.batch_size)                       \n",
    "    return val_data\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n",
    "    test_data = DataLoader(dataset, num_workers=7, persistent_workers=True, batch_size = self.batch_size)                   \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# this cell is from the source notebook, we changed the input dataset variables\n",
    "\n",
    "# create an instance of the data summary class using our datasets\n",
    "summary_data = SummaryDataModule(tokenizer, df_train_short, df_test_short, df_val_short, batch_size = 16)\n",
    "\n",
    "# create an instance of the model\n",
    "model = LitModel(learning_rate=2e-5, tokenizer=tokenizer, model=bart_model, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# this cell is from the source notebook, it was modified through trial and error to find the setup that worked best with our model\n",
    "\n",
    "# create a training instance of our model, hyperparameters were modified from the source code\n",
    "# we tried one epoch first because the source code used one epoch and was able to get good results and even training for only one epoch still took almost 4 hours\n",
    "trainer = pl.Trainer(logger=False,\n",
    "                     max_epochs = 1,\n",
    "                     min_epochs = 1,\n",
    "                     enable_model_summary=True,\n",
    "                     enable_progress_bar=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 139 M \n",
      "-------------------------------------------------------\n",
      "139 M     Trainable params\n",
      "0         Non-trainable params\n",
      "139 M     Total params\n",
      "557.682   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4375/4375 [3:44:04<00:00,  0.33it/s]             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4375/4375 [3:44:13<00:00,  0.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1#scrollTo=t77cjYY_fZlb\n",
    "\n",
    "# this is the last cell referencing the source notebook\n",
    "\n",
    "# fit the instance of our model to the dataset instance\n",
    "trainer.fit(model, summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of using that source notebook - trying out the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version OF runBart function, updated from our baseline model for improved speed and performance\n",
    "# testing and trial and error showed that removing the component of the function that calculated a unique maxlength for every summary sped up prediction generation significantly\n",
    "# in the baseline model we had issues with large numbers of NaN empty summary predictions,\n",
    "# through some research, testing, and trial and error we were able to find a configuration for the encode and generate() steps that corrected this issue\n",
    "\n",
    "def runBart(df):\n",
    "\n",
    "    # Empty lists for predictions and performance timestamps\n",
    "    predictions = []\n",
    "    times = []\n",
    "\n",
    "    # For the number of rows in the given dataframe\n",
    "    for i in range(len(df)):\n",
    "        # Create a start timestamp\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Create a document instance using the row's entry for the stringified document\n",
    "        doc = df.iloc[i][\"document\"]\n",
    "\n",
    "        # Encoding inputs using BART tokenizer \n",
    "        inputs = tokenizer.encode(doc, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "        # Generate vectorized summary using encoded inputs\n",
    "        summary_ids = model.generate_text(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "        # Decode the summary into a human-readable format\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Append the predicted summary to a list of predictions\n",
    "        predictions.append(summary)\n",
    "\n",
    "        # Create an end timestamp\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        # Calculate computation speed\n",
    "        speed = end - start\n",
    "\n",
    "        # Append computation speed to list\n",
    "        times.append(speed)\n",
    "\n",
    "        # If the iteration is a multiple of 1000\n",
    "        if i % 5000 == 0:\n",
    "            # Calculate the average computation time per row so far and print\n",
    "            avg_time = sum(times) / len(times)\n",
    "            print(\"Average time per row at\", i, \"row:\", avg_time)\n",
    "\n",
    "    # Create a new column for the dataframe using the predictions generated and return the modified dataframe\n",
    "    df[\"BART_Pred\"] = predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per row at 0 row: 2.058996300000217\n",
      "Average time per row at 5000 row: 1.918337959508114\n",
      "Average time per row at 10000 row: 1.9208283956404233\n",
      "Average time per row at 15000 row: 1.9187569718818536\n",
      "Average time per row at 20000 row: 1.9171497695365232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>BART_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>japanese electronics giant toshiba said tuesda...</td>\n",
       "      <td>toshiba profits  times up in third quarter</td>\n",
       "      <td>toshiba net profits grow more than  times yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>michael campbell opened a unk lead on defendin...</td>\n",
       "      <td>campbell puts defending champion woosnam in tr...</td>\n",
       "      <td>campbell leads woosnam after  holes in quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>iran on tuesday dismissed the allegation by th...</td>\n",
       "      <td>iran denies allegation on its military deployment</td>\n",
       "      <td>iran dismisses alawsat claim on southern bord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>turkish foreign minister and deputy prime mini...</td>\n",
       "      <td>turkish fm hails eu plan to end economic sanct...</td>\n",
       "      <td>turkish fm says eu proposal on cypriot cyprio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>patricia mcgovern  the former senate ways and ...</td>\n",
       "      <td>former senator joins governor race</td>\n",
       "      <td>mcgovern announces campaign for governor of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>three activists are charged with staging an un...</td>\n",
       "      <td>charges against activists could set precedent ...</td>\n",
       "      <td>hong kong activists charged with unauthorized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>a prominent fatah leader and his   yearold son...</td>\n",
       "      <td>father son killed in fatahhamas fight in gaza</td>\n",
       "      <td>fatah leader hamas killed in gaza city fighti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>trustees at virginia union university  one of ...</td>\n",
       "      <td>wilder in running to head virginia union</td>\n",
       "      <td>virginia union trustees considering douglas w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>patrouille de france   lrb paf rrb the famous...</td>\n",
       "      <td>french famous unk to present aerobatics shows ...</td>\n",
       "      <td>china  aerobatic team to present aerobatics s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>the relentless insurgency in the sunni muslim ...</td>\n",
       "      <td>us troops battle resistance fighters west of b...</td>\n",
       "      <td>roadside bombings kill  american soldier in b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "5000   japanese electronics giant toshiba said tuesda...   \n",
       "5001   michael campbell opened a unk lead on defendin...   \n",
       "5002   iran on tuesday dismissed the allegation by th...   \n",
       "5003   turkish foreign minister and deputy prime mini...   \n",
       "5004   patricia mcgovern  the former senate ways and ...   \n",
       "...                                                  ...   \n",
       "29995  three activists are charged with staging an un...   \n",
       "29996  a prominent fatah leader and his   yearold son...   \n",
       "29997  trustees at virginia union university  one of ...   \n",
       "29998   patrouille de france   lrb paf rrb the famous...   \n",
       "29999  the relentless insurgency in the sunni muslim ...   \n",
       "\n",
       "                                                 summary  \\\n",
       "5000          toshiba profits  times up in third quarter   \n",
       "5001   campbell puts defending champion woosnam in tr...   \n",
       "5002   iran denies allegation on its military deployment   \n",
       "5003   turkish fm hails eu plan to end economic sanct...   \n",
       "5004                  former senator joins governor race   \n",
       "...                                                  ...   \n",
       "29995  charges against activists could set precedent ...   \n",
       "29996      father son killed in fatahhamas fight in gaza   \n",
       "29997           wilder in running to head virginia union   \n",
       "29998  french famous unk to present aerobatics shows ...   \n",
       "29999  us troops battle resistance fighters west of b...   \n",
       "\n",
       "                                               BART_Pred  \n",
       "5000    toshiba net profits grow more than  times yea...  \n",
       "5001    campbell leads woosnam after  holes in quarte...  \n",
       "5002    iran dismisses alawsat claim on southern bord...  \n",
       "5003    turkish fm says eu proposal on cypriot cyprio...  \n",
       "5004    mcgovern announces campaign for governor of t...  \n",
       "...                                                  ...  \n",
       "29995   hong kong activists charged with unauthorized...  \n",
       "29996   fatah leader hamas killed in gaza city fighti...  \n",
       "29997   virginia union trustees considering douglas w...  \n",
       "29998   china  aerobatic team to present aerobatics s...  \n",
       "29999   roadside bombings kill  american soldier in b...  \n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the model to generate predictions using the test set\n",
    "runBart(df_test_short)\n",
    "\n",
    "df_test_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were 0 empty predictions generated.\n"
     ]
    }
   ],
   "source": [
    "# check generated predictions for NaN values\n",
    "\n",
    "# count null values in BART pred columnm\n",
    "null_predictions = df_test_short['BART_Pred'].isna().sum()\n",
    "\n",
    "print(\"there were\", null_predictions, \"empty predictions generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improvement over our baseline model, which generated a large number of null values as predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTScore Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize BERTScore metric\n",
    "\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 482/482 [00:00<00:00, 161kB/s]\n",
      "C:\\Users\\cmoor197\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cmoor197\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 11.2MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 61.3MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 48.7MB/s]\n",
      "model.safetensors: 100%|██████████| 1.42G/1.42G [00:12<00:00, 110MB/s] \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# generating BERTScore metrics for model predictions\n",
    "\n",
    "# create list of prediction outputs\n",
    "test_predictions = list(df_test_short[\"BART_Pred\"].astype(str))\n",
    "# create list of true outputs\n",
    "test_references = list(df_test_short[\"summary\"].astype(str))\n",
    "# calculate BERTScore values comparing model predictions with true summaries\n",
    "test_results_bert = bertscore.compute(predictions=test_predictions, references=test_references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set result:\n",
      "Average precision is 0.8033035963749886\n",
      "test set result:\n",
      "Average recall is 0.8921198317599297\n",
      "test set result:\n",
      "Average f1 is 0.8449282884764672\n"
     ]
    }
   ],
   "source": [
    "# calculate average precision, recall and F1 scores from BERTScore model based on model predictions\n",
    "\n",
    "# create list of result keys\n",
    "test_keys = list(test_results_bert.keys())\n",
    "\n",
    "# for number of values in keylist-1\n",
    "for k in range(len(test_keys)-1):\n",
    "    # sum total of all result values\n",
    "    s_test = sum(test_results_bert[test_keys[k]])\n",
    "    # calculate the total number of result values\n",
    "    le_test = len(test_results_bert[test_keys[k]])\n",
    "    # compute average result value\n",
    "    avg_test = s_test/le_test\n",
    "\n",
    "    print(\"test set result:\")\n",
    "    print(\"Average {} is {}\".format(test_keys[k], avg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ROUGE metrics model\n",
    "\n",
    "rouge = load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set results:\n",
      "{'rouge1': 0.20933892884082345, 'rouge2': 0.08089128435239316, 'rougeL': 0.18351244174179016, 'rougeLsum': 0.18348750351265208}\n"
     ]
    }
   ],
   "source": [
    "# generate ROUGE metrics scores for train and test model outputs\n",
    "\n",
    "# compute ROUGE metrics scores comparing model predictions with true outputs\n",
    "test_results_rouge = rouge.compute(predictions=test_predictions, references=test_references)\n",
    "\n",
    "print(\"test set results:\")\n",
    "print(test_results_rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe a few specific model predictions for human evaluation\n",
    "\n",
    "We wanted to view a few of the model predictions beside their target outputs and the original inputs to see how the model performed by human standards, as metrics can only convey so much meaning in evaluating high-level NLP tasks by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13441, 705, 23703, 20834, 21140]\n",
      "\n",
      "index: 13441\n",
      "original input: steve mcmanaman might get back into the england team after all \n",
      "target summary: england offers hope for recall of real madrid star\n",
      "model prediction:  steve mcmanaman might get back into england team after all that time has passed  mcmanmanaman may get back in the lineup after all this time he has been out of the netherlands with england this year \n",
      "\n",
      "index: 705\n",
      "original input: the federal reserve bank of new york has taken disciplinary action against jp morgan amp co \n",
      "target summary: jp morgan disciplined for loans to sumitomo trader\n",
      "model prediction:  federal bank of new york takes disciplinary action against jp morgan co  co  bank of cambodia bank says he  bank should not be allowed to do business in the state banking system for  years or face loss of millions\n",
      "\n",
      "index: 23703\n",
      "original input: china will turn all their resources to the th asian women  basketball championships  which will open on may  in japan  to earn the only ticket to the sydney olympic games next year for the continent \n",
      "target summary: china women basketball team gears up for sydney games qualifier\n",
      "model prediction:  china to host th asian women  olympic games in japan to compete in sweden asiapacific championships in jakarta in august  asiad in jaiwan olympia in jamborea\n",
      "\n",
      "index: 20834\n",
      "original input: share prices rose in early trading on the london market thursday  underpinned by overnight gains on wall street and a rally in gilts and the march futures contract  dealers said \n",
      "target summary: london shares higher on firmer futures gilts\n",
      "model prediction:  london stocks rise on wall street rally gilts march futures futures up  british britain down  pct aug aug   european bourse up  pcs up   bourse down  mln in early trading\n",
      "\n",
      "index: 21140\n",
      "original input: an internet piracy watchdog has called on the dutch judicial authorities to force five internet access providers to hand over personal data on people downloading music and films on a large scale \n",
      "target summary: dutch watchdog seeks court action to track down internet pirates\n",
      "model prediction:  piracy watchdog calls on dutch court to force internet access providers to hand over personal data on music and films on large scale of internet piracy data seized in dutch internet service sale  pirated copies of unk to dutch piracy watchdog says\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# produce five random input/target/prediction pairs from the model\n",
    "\n",
    "# empty list for index sample\n",
    "indexList = []\n",
    "\n",
    "# generate five random index values and add to list\n",
    "for i in range(5):\n",
    "    index = random.randint(0,25000)\n",
    "    indexList.append(index)\n",
    "\n",
    "print(indexList)\n",
    "print()\n",
    "\n",
    "# for index in list\n",
    "for ind in indexList:\n",
    "    # display the original input, the target summary, and what the model predicted for a summary\n",
    "    print(\"index:\", ind)\n",
    "    print(\"original input:\", df_test_short.iloc[ind][\"document\"])\n",
    "    print(\"target summary:\", df_test_short.iloc[ind][\"summary\"])\n",
    "    print(\"model prediction:\", df_test_short.iloc[ind][\"BART_Pred\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Results\n",
    "*(from canvas) \"How does your model perform on the metrics you have chosen from your previous submission?\"*\n",
    "\n",
    "As can be seen above, disappointingly, our model, after one epoch of fine-tuning/training, did not perform very well in comparison to our baseline model. BERTScore recall did increase by 3% (from 86 to 89), but all other metrics dropped by a few percentage points. However, it is worth noting that our baseline model produced an extremely large number of null values (and this one produced none !), which would skew the way these metrics would evaluate the model, so a direct comparison is not as meaningful as it could be. \n",
    "\n",
    "As was discussed in class, numeric n-gram based metrics like ROUGE can only be so valuable for complex NLP tasks like text summarization, as a model can semantically capture a target value without necessarily using the same words or grammar structure, so we are not as discouraged that these scores are lower than the baseline. The BERTScore value, however, is semantic, so this score decreasing is more disheartening. Something we did find interesting was actually reading the model outputs vs the target summaries vs the original inputs ourselves, as this seems to paint a better picture of where the model is in terms of learning and how it is performing. As can be seen in the examples above, the model is capable of producing (mostly) coherent summaries pretty consistently, so that is encouraging. Something we thought was interesting was the way that the model's summary predictions are often longer than the original input text. We realized, a little too late in the project process, that the dataset we chose for this project has entries to be summarized that are, on average, very short (typically no more than a few sentences). We believe this may have been preventative in the model's learning, and makes the task of summarization much more difficult for the model than it would be with a larger corpus of text (which provides more context, and more content for the model to condense into shorthand that makes sense). \"Summarizing\" one sentence in one sentence is difficult, even for a human. We have learned about text summarization throughout the semester, and have a much better understanding of the kind of data that is best suited for this task now than we did in August.\n",
    "\n",
    "Another note based on reading the model's outputs - the model frequently fixated on a word or n-gram and repeated itself several times in a way that sort of \"padded\" summaries in garbage filler. We do believe that this behavior could be lessened with additional and more thorough model training. We only ran our training fit() process for one epoch, with 70,000 rows of training data, and this still took almost 4 hours to complete. This, when combined with the over 14 hours required to run the remaining components of the notebook, made for an over 18 hour process from start to finish. A model test run taking that long was extremely restrictive when it came to testing, debugging, and trial-and-error adjustments, so for the sake of turning the assignment in on time we had to settle for lower performance than we wanted. We are, however, going to continue running the model with additional epochs and more training data until the time of the final project presentation, just to see if we can improve model performance more. If we are able to get better numbers we will report these in our final report and presentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
